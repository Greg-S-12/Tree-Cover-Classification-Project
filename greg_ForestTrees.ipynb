{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image  \n",
    "from pydotplus import graph_from_dot_data\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Downloads/covtype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points     ...      Soil_Type32  Soil_Type33  \\\n",
       "0                                6279     ...                0            0   \n",
       "1                                6225     ...                0            0   \n",
       "2                                6121     ...                0            0   \n",
       "3                                6211     ...                0            0   \n",
       "4                                6172     ...                0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40', 'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = df.profile_report(title='Pandas Profiling Report', plot={'histogram': {'bins': 8}})\n",
    "# profile.to_file(output_file=\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    283301\n",
       "1    211840\n",
       "3     35754\n",
       "7     20510\n",
       "6     17367\n",
       "5      9493\n",
       "4      2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cover_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = df['Cover_Type']\n",
    "# s.replace([1, 3, 4,5,6,7], 0, inplace=True)\n",
    "# s.replace([2], 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    283301\n",
       "1    211840\n",
       "3     35754\n",
       "7     20510\n",
       "6     17367\n",
       "5      9493\n",
       "4      2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Cover_Type']\n",
    "X = df.loc[:, df.columns != 'Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                    random_state=42)\n",
    "ss = MinMaxScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=42))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(fit_intercept=False, C=1e12,class_weight='balanced', solver='liblinear')\n",
    "\n",
    "\n",
    "model_log = logreg.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred_train = logreg.predict(X_train_sc)\n",
    "y_pred = logreg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35846, 12432,    41,     0,   654,   316,  3717],\n",
       "       [14206, 49609,  1903,    27,  2778,  1944,   309],\n",
       "       [    0,   367,  6273,   581,   116,  1572,     0],\n",
       "       [    0,     0,   189,   402,     0,    60,     0],\n",
       "       [   35,  1213,   247,     0,   904,    74,     0],\n",
       "       [    0,   407,  1451,   233,   175,  2107,     0],\n",
       "       [  930,    24,    21,     0,     0,     0,  4090]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-de95e8015d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate the fpr, tpr, and thresholds for the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate the probability scores of each point in the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the probability scores of each point in the training set\n",
    "y_train_score = model_log.decision_function(X_train_sc)\n",
    "\n",
    "# Calculate the fpr, tpr, and thresholds for the training set\n",
    "train_fpr, train_tpr, thresholds = roc_curve(y_train, y_train_score)\n",
    "\n",
    "# Calculate the probability scores of each point in the test set\n",
    "y_test_score = model_log.decision_function(X_test_sc)\n",
    "\n",
    "# Calculate the fpr, tpr, and thresholds for the test set\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for test set\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve for Test Set')\n",
    "plt.legend(loc='lower right')\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "print('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(y_test, y_pred, labels=[\"Class 1\", \"Class 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_train = metrics.recall_score(y_train, y_pred_train)\n",
    "Precision_train = metrics.precision_score(y_train, y_pred_train)\n",
    "print ('Training Recall score:{:.2f}'.format(Recall_train)) \n",
    "print ('Training Precision score:{:.2f}'.format(Precision_train)) \n",
    "print('\\n')\n",
    "Recall_test= metrics.recall_score(y_test, y_pred)\n",
    "Precision_test = metrics.precision_score(y_test, y_pred)\n",
    "print ('Test Recall score :{:.2f}'.format(Recall_test))\n",
    "print('Test Precision score: {:.2f}'.format(Precision_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier, fit it on the training data and make predictions on the test set\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3,class_weight='balanced' )\n",
    "\n",
    "clf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train_sc)\n",
    "y_pred_test = clf.predict(X_test_sc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_test)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print('\\n Test AUC is :{0}'.format(round(roc_auc, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DOT data\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                           feature_names=X.columns,  \n",
    "                           class_names=np.unique(y).astype('str'), \n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_train = metrics.recall_score(y_train, y_pred_train)\n",
    "Precision_train = metrics.precision_score(y_train, y_pred_train)\n",
    "print ('Training Recall score:{:.2f}'.format(Recall_train)) \n",
    "print ('Training Precision score:{:.2f}'.format(Precision_train)) \n",
    "print('\\n')\n",
    "Recall_test= metrics.recall_score(y_test, y_pred_test)\n",
    "Precision_test = metrics.precision_score(y_test, y_pred_test)\n",
    "print ('Test Recall score :{:.2f}'.format(Recall_test))\n",
    "print('Test Precision score: {:.2f}'.format(Precision_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth':range(1,5),'min_samples_leaf':[5,10,15]}\n",
    "\n",
    "opt_model = GridSearchCV(clf,param_grid,cv=3,scoring='accuracy')\n",
    "opt_model.fit(X_train_sc,y_train)\n",
    "best_model = opt_model.best_estimator_\n",
    "\n",
    "opt_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decT = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=5, class_weight='balanced')\n",
    "\n",
    "decT.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_predT = decT.predict(X_train_sc) \n",
    "y_hat_pred = decT.predict(X_test_sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = metrics.accuracy_score(y_train, y_hat_predT)\n",
    "f1_score_train= metrics.f1_score(y_train, y_hat_predT, average=\"weighted\")\n",
    "print('Training Accuracy: {:.2f}'.format(accuracy1))\n",
    "print ('Training F1 score:{:.2f}'.format(f1_score_train)) \n",
    "\n",
    "print('\\n')\n",
    "\n",
    "f1_score= metrics.f1_score(y_test, y_hat_pred, average=\"weighted\")\n",
    "accuracy2 = metrics.accuracy_score(y_test, y_hat_pred)\n",
    "print ('Test F1 score:{:.2f}'.format(f1_score))\n",
    "print('Test Accuracy: {:.2f}'.format(accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 30, 30, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion='gini', max_depth=max_depth, random_state=42, class_weight='balanced')\n",
    "   dt.fit(X_train_sc, y_train)\n",
    "   train_pred = dt.predict(X_train_sc)\n",
    "   \n",
    "   acc = accuracy_score(y_train,train_pred) * 100\n",
    "   # Add acc score to previous train results\n",
    "   train_results.append(acc)\n",
    "   y_pred = dt.predict(X_test_sc)\n",
    "   \n",
    "   acc = accuracy_score(y_test,y_pred) * 100\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(acc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(max_depths, train_results, 'b', label='Train Accuracy')\n",
    "plt.plot(max_depths, test_results, 'r', label='Test Accuracy')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(1, 10, 10, endpoint=True, dtype=int)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   dt = DecisionTreeClassifier(criterion='gini', min_samples_leaf=min_samples_leaf, random_state=42, class_weight='balanced')\n",
    "   dt.fit(X_train_sc, y_train)\n",
    "   train_pred = dt.predict(X_train_sc)\n",
    "   acc_train = accuracy_score(y_train,train_pred) * 100   \n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test_sc)\n",
    "   acc_test = accuracy_score(y_test,y_pred) * 100   \n",
    "   test_results.append(acc_test)\n",
    "    \n",
    "plt.figure(figsize=(12,6))    \n",
    "plt.plot(min_samples_leafs, train_results, 'b', label='Train Accuracy')\n",
    "plt.plot(min_samples_leafs, test_results, 'r', label='Test Accuracy')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.xlabel('Min. Sample Leafs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree =  BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=25), \n",
    "                                 n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, max_depth= 25)\n",
    "forest.fit(X_train_sc, y_train)\n",
    "y_pred_train = forest.predict(X_train_sc)\n",
    "y_pred_test = forest.predict(X_test_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score= metrics.f1_score(y_test, y_hat_pred, average=\"weighted\")\n",
    "accuracy2 = metrics.accuracy_score(y_test, y_hat_pred)\n",
    "print ('Test F1 score:{:.2f}'.format(f1_score))\n",
    "print('Test Accuracy: {:.2f}'.format(accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_acc=forest.score(y_train, y_pred_train)\n",
    "print('Training Accuracy: {:.2f}'.format(for_acc))\n",
    "print('\\n')\n",
    "\n",
    "for_acc2=forest.score(y_test, y_pred_test)\n",
    "print('Test Accuracy: {:.2f}'.format(for_acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.linspace(1, 30, 30, endpoint=True, dtype=int)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for n_estimator in n_estimators:\n",
    "    forest = RandomForestClassifier(n_estimators=n_estimator, max_depth= 25)   \n",
    "    forest.fit(X_train_sc, y_train)\n",
    "    train_pred = forest.predict(X_train_sc)\n",
    "    acc_train = accuracy_score(y_train,train_pred) * 100   \n",
    "    train_results.append(acc_train)\n",
    "    y_pred = forest.predict(X_test_sc)\n",
    "    acc_test = accuracy_score(y_test,y_pred) * 100   \n",
    "    test_results.append(acc_test)\n",
    "    \n",
    "plt.figure(figsize=(12,6))    \n",
    "plt.plot(n_estimators, train_results, 'b', label='Train Accuracy')\n",
    "plt.plot(n_estimators, test_results, 'r', label='Test Accuracy')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.title('n_estimators vs Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
